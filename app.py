import streamlit as st
import PyPDF2
import pdfplumber
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import os
import google.generativeai as genai
from datetime import datetime

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Tax Chatbot FGV - Especialista TributÃ¡rio",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ConfiguraÃ§Ã£o do Gemini 
GEMINI_API_KEY = "AIzaSyAiZS9q4IZ3TfxI5GCIX8p_g3P_nmHisL4I"  

class TaxAIChatbot:
    def __init__(self):
        self.documents_path = "documents"
        self.vector_store = None
        self.setup_gemini()
    
    def setup_gemini(self):
        """Configura a API do Gemini"""
        try:
            genai.configure(api_key=GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-pro')
            return True
        except Exception as e:
            st.error(f"Erro na configuraÃ§Ã£o do Gemini: {e}")
            return False
    
    def extract_text_from_pdf(self, pdf_path):
        """Extrai texto de arquivos PDF"""
        text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
        except Exception as e:
            try:
                with open(pdf_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    for page in pdf_reader.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
            except Exception as e2:
                st.error(f"Erro no PDF {os.path.basename(pdf_path)}: {e2}")
                return ""
        return text

    def load_and_process_documents(self):
        """Carrega e processa todos os PDFs"""
        if not os.path.exists(self.documents_path):
            st.error(f"âŒ Pasta '{self.documents_path}' nÃ£o encontrada!")
            return None
        
        pdf_files = [f for f in os.listdir(self.documents_path) if f.lower().endswith('.pdf')]
        
        if not pdf_files:
            st.error("âŒ Nenhum PDF encontrado")
            return None
        
        all_texts = []
        for pdf_file in pdf_files:
            pdf_path = os.path.join(self.documents_path, pdf_file)
            text = self.extract_text_from_pdf(pdf_path)
            if text and len(text.strip()) > 50:
                all_texts.append({
                    'filename': pdf_file,
                    'content': text,
                    'size': len(text)
                })
                st.success(f"âœ… {pdf_file} - {len(text)} caracteres")
        
        return all_texts

    def create_vector_store(self, documents):
        """Cria o vector store para busca semÃ¢ntica"""
        if not documents:
            return None
        
        texts = [doc['content'] for doc in documents]
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            length_function=len
        )
        
        chunks = []
        for text in texts:
            chunks.extend(text_splitter.split_text(text))
        
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        vector_store = FAISS.from_texts(chunks, embeddings)
        return vector_store

    def search_relevant_documents(self, question, k=5):
        """Busca documentos relevantes para a pergunta"""
        if not self.vector_store:
            return []
        
        docs = self.vector_store.similarity_search(question, k=k)
        return docs

    def generate_ai_response(self, question, context, conversation_history=[]):
        """Gera resposta usando Gemini AI com contexto especÃ­fico"""
        
        # Prepara o histÃ³rico de conversa
        history_text = ""
        if conversation_history:
            history_text = "\nHistÃ³rico recente:\n"
            for msg in conversation_history[-4:]:  # Ãšltimas 4 mensagens
                history_text += f"{msg['role']}: {msg['content']}\n"
        
        prompt = f"""
        VOCÃŠ Ã‰: Um especialista em legislaÃ§Ã£o tributÃ¡ria brasileira, trabalhando para a FGV.
        
        CONTEXTO LEGAL DISPONÃVEL:
        {context}
        
        {history_text}
        
        PERGUNTA ATUAL: {question}
        
        INSTRUÃ‡Ã•ES ESPECÃFICAS:
        
        1. **SE A PERGUNTA FOR SOBRE TRIBUTAÃ‡ÃƒO:**
           - Baseie-se STRITAMENTE no contexto fornecido
           - Cite artigos, leis e dispositivos especÃ­ficos quando possÃ­vel
           - Seja tÃ©cnico, preciso e atual
           - Formate a resposta de forma clara com tÃ³picos se necessÃ¡rio
        
        2. **SE A PERGUNTA NÃƒO ENCONTRAR BASE NO CONTEXTO:**
           - Identifique que a informaÃ§Ã£o especÃ­fica nÃ£o estÃ¡ nos documentos carregados
           - OfereÃ§a uma explicaÃ§Ã£o geral baseada em conhecimentos tributÃ¡rios
           - Sugira onde o usuÃ¡rio poderia encontrar essa informaÃ§Ã£o
           - Seja honesto sobre as limitaÃ§Ãµes
        
        3. **SE A PERGUNTA FOR FORA DO CONTEXTO TRIBUTÃRIO:**
           - Eduque gentilmente o usuÃ¡rio sobre o escopo do chatbot
           - OfereÃ§a redirecionamento para questÃµes tributÃ¡rias
           - Mantenha-se profissional e Ãºtil
        
        4. **FORMATO DA RESPOSTA:**
           - Seja direto e objetivo
           - Use marcadores para listas
           - Destaque termos importantes em **negrito**
           - Inclua referÃªncias quando aplicÃ¡vel
        
        RESPOSTA:
        """
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"âŒ Erro na geraÃ§Ã£o da resposta: {str(e)}"

def initialize_system():
    """Inicializa o sistema completo"""
    st.title("ğŸ¤– Tax Chatbot FGV - Especialista em TributaÃ§Ã£o")
    st.markdown("---")
    
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = TaxAIChatbot()
        st.session_state.initialized = False
        st.session_state.conversation_history = []
    
    chatbot = st.session_state.chatbot
    
    # InicializaÃ§Ã£o do sistema
    if not st.session_state.initialized:
        with st.expander("ğŸ”§ InicializaÃ§Ã£o do Sistema", expanded=True):
            st.info("ğŸ”„ Iniciando sistema de IA tributÃ¡ria...")
            
            # Configura Gemini
            if not chatbot.setup_gemini():
                st.error("âŒ Falha na configuraÃ§Ã£o da IA")
                return None
            
            # Carrega documentos
            with st.spinner("ğŸ“‚ Carregando documentos tributÃ¡rios..."):
                documents = chatbot.load_and_process_documents()
                
                if not documents:
                    st.error("ğŸš« NÃ£o foi possÃ­vel carregar documentos")
                    return None
                
                st.success(f"ğŸ“š {len(documents)} documentos carregados")
            
            # Cria vector store
            with st.spinner("ğŸ§  Criando base de conhecimento..."):
                chatbot.vector_store = chatbot.create_vector_store(documents)
                st.session_state.initialized = True
                st.success("âœ… Sistema de IA inicializado com sucesso!")
    
    return chatbot

def main():
    """FunÃ§Ã£o principal"""
    
    chatbot = initialize_system()
    
    if chatbot is None:
        st.error("""
        âŒ **Sistema nÃ£o pode ser inicializado**
        
        **Verifique:**
        1. API Key do Gemini configurada
        2. Pasta 'documents' com PDFs vÃ¡lidos
        3. ConexÃ£o com internet
        """)
        return
    
    # Sidebar
    st.sidebar.title("âš™ï¸ ConfiguraÃ§Ãµes")
    st.sidebar.success("âœ… IA Ativa - Gemini Pro")
    
    # Controles de busca
    st.sidebar.subheader("ğŸ” ConfiguraÃ§Ãµes de Busca")
    search_depth = st.sidebar.slider("Profundidade da busca", 3, 8, 5)
    temperature = st.sidebar.slider("Criatividade da resposta", 0.1, 1.0, 0.3)
    
    # Ãrea de chat
    st.header("ğŸ’¬ Consultoria TributÃ¡ria")
    
    # HistÃ³rico de conversa
    if st.session_state.conversation_history:
        st.subheader("ğŸ“ Conversa Recente")
        for msg in st.session_state.conversation_history[-6:]:
            with st.chat_message("user" if msg["role"] == "user" else "assistant"):
                st.write(msg["content"])
    
    # Input da pergunta
    question = st.chat_input("Digite sua pergunta sobre tributaÃ§Ã£o...")
    
    if question:
        # Adiciona pergunta ao histÃ³rico
        st.session_state.conversation_history.append({
            "role": "user", 
            "content": question,
            "timestamp": datetime.now().isoformat()
        })
        
        # Exibe pergunta do usuÃ¡rio
        with st.chat_message("user"):
            st.write(question)
        
        # Processa a resposta
        with st.chat_message("assistant"):
            with st.spinner("ğŸ” Consultando legislaÃ§Ã£o..."):
                # Busca documentos relevantes
                relevant_docs = chatbot.search_relevant_documents(question, k=search_depth)
                
                if relevant_docs:
                    context = "\n\n".join([f"ğŸ“„ Documento {i+1}:\n{doc.page_content}" 
                                         for i, doc in enumerate(relevant_docs)])
                    
                    st.info(f"ğŸ“š Encontradas {len(relevant_docs)} fontes relevantes")
                else:
                    context = "Nenhum documento especÃ­fico encontrado para esta consulta."
                    st.warning("âš ï¸ Consultando conhecimento geral de tributaÃ§Ã£o")
                
                # Gera resposta com IA
                with st.spinner("ğŸ§  Gerando resposta especializada..."):
                    response = chatbot.generate_ai_response(
                        question, 
                        context, 
                        st.session_state.conversation_history
                    )
                
                # Exibe resposta
                st.success("âœ… Resposta baseada em legislaÃ§Ã£o tributÃ¡ria")
                st.write(response)
                
                # Mostrar fontes (expandÃ­vel)
                with st.expander("ğŸ“‹ Fontes Consultadas"):
                    for i, doc in enumerate(relevant_docs):
                        st.markdown(f"**Fonte {i+1}:**")
                        st.text(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                        st.markdown("---")
        
        # Adiciona resposta ao histÃ³rico
        st.session_state.conversation_history.append({
            "role": "assistant", 
            "content": response,
            "timestamp": datetime.now().isoformat()
        })
    
    # Ãrea de informaÃ§Ãµes
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¡ Dicas de Uso")
    st.sidebar.info("""
    **Exemplos de perguntas:**
    - "Qual a alÃ­quota do IRPF para 2024?"
    - "Explique o Simples Nacional"
    - "Prazos para declaraÃ§Ã£o do IR"
    - "DiferenÃ§a entre lucro real e presumido"
    """)
    
    # EstatÃ­sticas
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š EstatÃ­sticas")
    st.sidebar.text(f"ğŸ’¬ Mensagens: {len(st.session_state.conversation_history)}")
    st.sidebar.text(f"ğŸ“š Documentos: {len([f for f in os.listdir('documents') if f.endswith('.pdf')])}")

if __name__ == "__main__":
    main()
