import streamlit as st
import PyPDF2
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import os
import time

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Tax Chatbot FGV",
    page_icon="ü§ñ",
    layout="wide"
)

class TaxDocumentProcessor:
    def __init__(self):
        self.documents_path = "documents"
        self.vector_store = None
    
    def extract_text_from_pdf(self, pdf_path):
        """Extrai texto de arquivos PDF"""
        text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"--- P√°gina {page_num + 1} ---\n{page_text}\n\n"
        except Exception as e:
            st.warning(f"Erro com pdfplumber em {os.path.basename(pdf_path)}: {e}")
            try:
                with open(pdf_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    for page_num, page in enumerate(pdf_reader.pages):
                        page_text = page.extract_text()
                        if page_text:
                            text += f"--- P√°gina {page_num + 1} ---\n{page_text}\n\n"
            except Exception as e2:
                st.error(f"Erro cr√≠tico no PDF {os.path.basename(pdf_path)}: {e2}")
                return ""
        
        return text

    def load_and_process_documents(self):
        """Carrega e processa todos os PDFs da pasta documents"""
        # Verifica se a pasta documents existe
        if not os.path.exists(self.documents_path):
            st.error(f"‚ùå Pasta '{self.documents_path}' n√£o encontrada!")
            st.info("üëâ Crie uma pasta chamada 'documents' e adicione os PDFs l√°")
            return None
        
        # Lista todos os PDFs
        pdf_files = [f for f in os.listdir(self.documents_path) if f.lower().endswith('.pdf')]
        
        if not pdf_files:
            st.error(f"‚ùå Nenhum arquivo PDF encontrado na pasta '{self.documents_path}'")
            st.info("üëâ Adicione arquivos PDF na pasta 'documents'")
            return None
        
        st.success(f"üìö Encontrados {len(pdf_files)} documentos PDF")
        
        all_texts = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Processa cada PDF
        for i, pdf_file in enumerate(pdf_files):
            pdf_path = os.path.join(self.documents_path, pdf_file)
            status_text.text(f"üìñ Processando: {pdf_file}...")
            
            text = self.extract_text_from_pdf(pdf_path)
            if text and len(text.strip()) > 50:
                all_texts.append(text)
                st.info(f"‚úÖ {pdf_file} - {len(text)} caracteres extra√≠dos")
            else:
                st.warning(f"‚ö†Ô∏è {pdf_file} - Pouco texto extra√≠do ou PDF pode ser imagem")
            
            progress_bar.progress((i + 1) / len(pdf_files))
        
        status_text.text("‚úÖ Processamento conclu√≠do!")
        return all_texts

    def create_vector_store(self, texts):
        """Cria o vector store a partir dos textos"""
        if not texts:
            return None
        
        with st.spinner("üîß Dividindo textos em partes menores..."):
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=800,
                chunk_overlap=100,
                length_function=len
            )
            
            chunks = []
            for text in texts:
                chunks.extend(text_splitter.split_text(text))
            
            st.info(f"üìù Criados {len(chunks)} segmentos de texto")

        with st.spinner("üß† Criando representa√ß√µes num√©ricas do texto..."):
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
            
            vector_store = FAISS.from_texts(chunks, embeddings)
        
        return vector_store

def initialize_system():
    """Inicializa o sistema completo"""
    st.title("ü§ñ Tax Chatbot FGV - Legisla√ß√£o Tribut√°ria")
    st.markdown("---")
    
    # Verifica se j√° est√° inicializado
    if 'initialized' in st.session_state and st.session_state.initialized:
        st.sidebar.success("‚úÖ Sistema j√° inicializado")
        return st.session_state.vector_store
    
    # Processo de inicializa√ß√£o
    with st.expander("üîß Status do Sistema", expanded=True):
        st.info("Inicializando sistema...")
        
        processor = TaxDocumentProcessor()
        
        with st.spinner("üìÇ Carregando documentos..."):
            texts = processor.load_and_process_documents()
            
            if not texts:
                st.error("üö´ N√£o foi poss√≠vel carregar os documentos")
                return None
            
            st.success(f"üìÑ {len(texts)} documentos carregados com sucesso")
        
        with st.spinner("ü§ñ Preparando base de conhecimento..."):
            vector_store = processor.create_vector_store(texts)
            
            if vector_store:
                st.session_state.vector_store = vector_store
                st.session_state.initialized = True
                st.success("‚úÖ Sistema inicializado com sucesso!")
                return vector_store
            else:
                st.error("‚ùå Falha ao criar base de conhecimento")
                return None

def main():
    """Fun√ß√£o principal da aplica√ß√£o"""
    
    # Inicializa o sistema
    vector_store = initialize_system()
    
    if vector_store is None:
        st.error("""
        ‚ùå **Sistema n√£o pode ser inicializado**
        
        **Solu√ß√µes poss√≠veis:**
        1. Crie uma pasta chamada `documents` na raiz do projeto
        2. Adicione arquivos PDF com texto extra√≠vel na pasta `documents`
        3. Verifique se os PDFs n√£o s√£o apenas imagens
        4. Execute `pip install -r requirements.txt` para instalar depend√™ncias
        """)
        return
    
    # Sidebar com informa√ß√µes
    st.sidebar.title("üìä Informa√ß√µes do Sistema")
    st.sidebar.success("‚úÖ Sistema operacional")
    st.sidebar.info("""
    **Documentos Carregados:**
    - Legisla√ß√£o Tribut√°ria
    - C√≥digo Tribut√°rio
    - Leis Fiscais
    - Regulamentos
    """)
    
    # √Årea principal de perguntas
    st.header("üí¨ Fa√ßa sua pergunta tribut√°ria")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        question = st.text_area(
            "**Descreva sua d√∫vida:**",
            placeholder="Ex: Qual a al√≠quota do Imposto de Renda para pessoa jur√≠dica em 2024?",
            height=120
        )
    
    with col2:
        st.markdown("### üí° Dicas")
        st.markdown("""
        - Seja espec√≠fico
        - Men√ß√£o artigos/laws
        - Contextualize a situa√ß√£o
        """)
        
        search_type = st.selectbox(
            "Tipo de busca:",
            ["Padr√£o", "Estrita", "Ampla"]
        )
    
    # Bot√£o de consulta
    if st.button("üîç Consultar Legisla√ß√£o", type="primary", use_container_width=True):
        if not question.strip():
            st.warning("‚ö†Ô∏è Por favor, digite uma pergunta")
            return
        
        with st.spinner("üîé Consultando base legislativa..."):
            # Busca documentos relevantes
            k = 3 if search_type == "Estrita" else 5 if search_type == "Ampla" else 4
            docs = vector_store.similarity_search(question, k=k)
            
            # Prepara contexto
            context = "\n\n".join([f"**Documento {i+1}:**\n{doc.page_content}" 
                                 for i, doc in enumerate(docs)])
            
            # Gera resposta
            response = generate_legal_response(question, context)
            
            # Exibe resultados
            st.markdown("## üìã Resposta Legal")
            st.success(response)
            
            # Mostra fontes
            with st.expander("üìö Fontes Consultadas", expanded=False):
                for i, doc in enumerate(docs):
                    st.markdown(f"### üìÑ Fonte {i+1}")
                    st.text(doc.page_content)
                    st.markdown("---")

def generate_legal_response(question, context):
    """Gera resposta baseada na legisla√ß√£o"""
    # SIMULA√á√ÉO - SUBSTITUA POR SEU MODELO LLM REAL
    
    prompt = f"""
    PERGUNTA DO USU√ÅRIO: {question}
    
    CONTEXTO LEGAL ENCONTRADO:
    {context}
    
    Por favor, forne√ßa uma resposta t√©cnica e precisa baseada exclusivamente no contexto fornecido.
    """
    
    # Resposta simulada - SUBSTITUA ISSO!
    resposta = f"""
    **An√°lise da Consulta:** "{question}"

    **Base Legal Consultada:**
    Foram analisados {len(context.split('**Documento'))-1} documentos da base legislativa tribut√°ria.

    **Resposta T√©cnica:**
    Com base na legisla√ß√£o tribut√°ria consultada, as informa√ß√µes relevantes foram extra√≠das dos documentos oficiais. Para uma resposta espec√≠fica sobre al√≠quotas, prazos, obriga√ß√µes acess√≥rias ou procedimentos fiscais, recomenda-se a consulta direta aos artigos e dispositivos legais mencionados nas fontes.

    **Observa√ß√£o:** Esta √© uma resposta simulada. Integre com seu modelo LLM para respostas precisas.

    *Fonte: Base de documentos tribut√°rios processados.*
    """
    
    return resposta

# Rodar a aplica√ß√£o
if __name__ == "__main__":
    main()